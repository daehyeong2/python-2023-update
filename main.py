import requests
from bs4 import BeautifulSoup

class Scrapper:
    def __init__(self):
        self.scrapped_keyword = []
        self.all_jobs = []
    def scrape_data(self, url):
        response = requests.get(url, headers={"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"})
        soup = BeautifulSoup(response.content, "html.parser")
        headers = soup.find_all("a", {"class": "preventLink"})[1::2]
        for header in headers:
            expired = bool(header.findNext("div", {"class": "description"}).find("strong", recursive=False))
            if expired:
                continue
            title = header.find("h2").text.replace("\t", "").replace("\n", "")
            company = header.findNext("h3", {"itemprop": "name"}).text.replace("\t", "").replace("\n", "")
            location = header.findNext("div", {"class": "location"}).text
            salary = header.findNext("div", string=lambda x: x and "ğŸ’°" in x).text.replace("*", "")
            url = "https://remoteok.com" + header["href"]
            if header["href"] == "/remote-jobs/":
                continue
            job_data = {
                title: title,
                company: company,
                location: location,
                salary: salary,
                url: url
            }
            self.all_jobs.append(job_data)
    def scrape(self, keyword, data_range):
        if data_range > 50: raise Exception("data_rangeëŠ” 50 ì´í•˜ì˜ ìˆ«ìë§Œ ë„£ì–´ì•¼ í•©ë‹ˆë‹¤.")
        if isinstance(keyword, list) and len(keyword) > 1:
            print(f"ì•½ {data_range*20*len(keyword)}ê°œì˜ ì¼ìë¦¬ë¥¼ ê²€ìƒ‰í•˜ê² ìŠµë‹ˆë‹¤. (ì¼ìë¦¬ê°€ {data_range*20*len(keyword)}ê°œë§Œí¼ ì—†ì–´ë„ ìµœëŒ€í•œ ê²€ìƒ‰í•©ë‹ˆë‹¤.)")
            for search_keyword in keyword:
                if search_keyword in self.scrapped_keyword: continue
                for offset in range(data_range):
                    print(f"{search_keyword}: {offset+1}í˜ì´ì§€ ìš”ì²­ ì¤‘.. ({offset+1}/{data_range})")
                    self.scrape_data(f"https://remoteok.com/?tags={search_keyword}&action=get_jobs&offset={offset*20}")
                self.scrapped_keyword.append(search_keyword)
        else:
            if isinstance(keyword, list): search_keyword = keyword[0]
            else: search_keyword = keyword
            if search_keyword in self.scrapped_keyword: return
            print(f"ì•½ {data_range*20}ê°œì˜ ì¼ìë¦¬ë¥¼ ê²€ìƒ‰í•˜ê² ìŠµë‹ˆë‹¤. (ì¼ìë¦¬ê°€ {data_range*20}ê°œë§Œí¼ ì—†ì–´ë„ ìµœëŒ€í•œ ê²€ìƒ‰í•©ë‹ˆë‹¤.)")
            for offset in range(data_range):
                print(f"{search_keyword}: {offset+1}í˜ì´ì§€ ìš”ì²­ ì¤‘.. ({offset+1}/{data_range})")
                self.scrape_data(f"https://remoteok.com/?tags={search_keyword}&action=get_jobs&offset={offset*20}")
            self.scrapped_keyword.append(search_keyword)
        print(f"{len(scrapper.all_jobs)}ê°œì˜ ì¼ìë¦¬ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

scrapper = Scrapper()

scrapper.scrape(
    keyword=["python", "react"],
    data_range=3
)